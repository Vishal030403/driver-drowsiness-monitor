{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc967751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eeb5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset_split'  # Folder containing 'train' and 'val'\n",
    "IMG_SIZE = (224, 224) # Standard size for MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20           # We need more than 1 epoch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531e796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # Normalize pixel values (0-1)\n",
    "    rotation_range=20,      # Rotate head slightly\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,         # Simulate distance changes\n",
    "    horizontal_flip=True,   # Left eye vs Right eye\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8948ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data:\n",
      "Found 37880 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Loading Training Data:\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'train'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',     # Binary classification (0 vs 1)\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a34b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Validation Data:\n",
      "Found 15030 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Validation Data:\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'val'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e88e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Mappings: {'Drowsy': 0, 'Non Drowsy': 1}\n"
     ]
    }
   ],
   "source": [
    "# --- CRITICAL CHECK ---\n",
    "# Ensure 'Closed' is 0 and 'Open' is 1\n",
    "print(\"\\nClass Mappings:\", train_generator.class_indices)\n",
    "# Expectation: {'Closed': 0, 'Open': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a443a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vishal\\OneDrive\\IdeaProjects\\driver drowsiness\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vishal\\OneDrive\\IdeaProjects\\driver drowsiness\\venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Building the Model (Transfer Learning)\n",
    "\n",
    "# 1. Download base model (MobileNetV2) without the top classification layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 2. Freeze the base model (so we don't destroy pre-trained patterns)\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcbbced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add our custom layers on top\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)       # Condense features\n",
    "x = Dense(128, activation='relu')(x)  # Learn complex patterns\n",
    "x = Dropout(0.5)(x)                   # Prevent overfitting\n",
    "outputs = Dense(1, activation='sigmoid')(x) # Output: 0.0 to 1.0\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842a4c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2422081 (9.24 MB)\n",
      "Trainable params: 164097 (641.00 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4. Compile\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), # Low learning rate for fine-tuning\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923948ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Training...\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Vishal\\OneDrive\\IdeaProjects\\driver drowsiness\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vishal\\OneDrive\\IdeaProjects\\driver drowsiness\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.8711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vishal\\OneDrive\\IdeaProjects\\driver drowsiness\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 3368s 3s/step - loss: 0.3180 - accuracy: 0.8711 - val_loss: 0.1275 - val_accuracy: 0.9811\n",
      "Epoch 2/20\n",
      "1184/1184 [==============================] - 2731s 2s/step - loss: 0.1203 - accuracy: 0.9659 - val_loss: 0.0669 - val_accuracy: 0.9891\n",
      "Epoch 3/20\n",
      "1184/1184 [==============================] - 2319s 2s/step - loss: 0.0719 - accuracy: 0.9813 - val_loss: 0.0485 - val_accuracy: 0.9907\n",
      "Epoch 4/20\n",
      "1184/1184 [==============================] - 2309s 2s/step - loss: 0.0500 - accuracy: 0.9874 - val_loss: 0.0291 - val_accuracy: 0.9941\n",
      "Epoch 5/20\n",
      "1184/1184 [==============================] - 2011s 2s/step - loss: 0.0376 - accuracy: 0.9903 - val_loss: 0.0204 - val_accuracy: 0.9953\n",
      "Epoch 6/20\n",
      "1184/1184 [==============================] - 1996s 2s/step - loss: 0.0285 - accuracy: 0.9930 - val_loss: 0.0156 - val_accuracy: 0.9951\n",
      "Epoch 7/20\n",
      "1184/1184 [==============================] - 2015s 2s/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0129 - val_accuracy: 0.9964\n",
      "Epoch 8/20\n",
      "1184/1184 [==============================] - 1995s 2s/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 9/20\n",
      "1184/1184 [==============================] - 2002s 2s/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
      "Epoch 10/20\n",
      "1184/1184 [==============================] - 1984s 2s/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
      "Epoch 11/20\n",
      "1184/1184 [==============================] - 1980s 2s/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
      "Epoch 12/20\n",
      "1184/1184 [==============================] - 1985s 2s/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 13/20\n",
      "1184/1184 [==============================] - 1999s 2s/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 14/20\n",
      "1184/1184 [==============================] - 2018s 2s/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
      "Epoch 15/20\n",
      "1184/1184 [==============================] - 2018s 2s/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "1184/1184 [==============================] - 2051s 2s/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
      "Epoch 17/20\n",
      "1184/1184 [==============================] - 2073s 2s/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 18/20\n",
      "1184/1184 [==============================] - 2034s 2s/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "1184/1184 [==============================] - 2072s 2s/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 20/20\n",
      "1184/1184 [==============================] - 2059s 2s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0032 - val_accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    # Stop if validation loss doesn't improve for 5 epochs\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    # Save the best model automatically\n",
    "    ModelCheckpoint('driver_drowsiness_final_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "print(\"ðŸš€ Starting Training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633b9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2422081 (9.24 MB)\n",
      "Trainable params: 164097 (641.00 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.save(\"driver_drowsiness_final_model.keras\")\n",
    "print(\"Model saved successfully!\")\n",
    "loaded = load_model(\"driver_drowsiness_final_model.keras\")\n",
    "\n",
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9fb560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training Complete\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Training Complete\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Cell 5: Visualization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m acc = \u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m val_acc = history.history[\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m loss = history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"âœ… Training Complete\")\n",
    "\n",
    "# Cell 5: Visualization\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Acc')\n",
    "plt.plot(val_acc, label='Validation Acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ddba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Test on a Single Image (Sanity Check)\n",
    "# This mimics what the backend does\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def predict_local_image(img_path =\"WIN_20251130_15_26_10_Pro.jpg\" ):\n",
    "    if not os.path.exists(img_path):\n",
    "        return\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # CRITICAL: Normalize exactly like training (1./255)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    val = prediction[0][0]\n",
    "    \n",
    "    print(f\"\\nImage: {img_path}\")\n",
    "    print(f\"Raw Value: {val:.4f}\")\n",
    "\n",
    "    \n",
    "    # Logic: 0=Closed, 1=Open\n",
    "    if val < 0.5:\n",
    "        print(\"Prediction: ðŸ˜´ DROWSY (Closed)\")\n",
    "    else:\n",
    "        print(\"Prediction: ðŸ‘€ ALERT (Open)\")\n",
    "\n",
    "# You can upload test images to the notebook folder and run this\n",
    "# predict_local_image('test_open.jpg')\n",
    "# predict_local_image('test_closed.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4503df68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: WIN_20251130_15_26_10_Pro.jpg\n",
      "Raw Value: 0.6437\n",
      "Prediction: ðŸ‘€ ALERT (Open)\n"
     ]
    }
   ],
   "source": [
    "predict_local_image(\"WIN_20251130_15_26_10_Pro.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3ceb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
